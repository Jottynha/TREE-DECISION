<h1 align="center">Trabalho Pr√°tico IA [Algoritmos] (2025/2)</h1>

<div align="center">

![Python](https://img.shields.io/badge/python-blue?style=for-the-badge&logo=python&logoColor=white)
![VS Code](https://img.shields.io/badge/visual%20studio%20code-blue?style=for-the-badge)
![Ubuntu](https://img.shields.io/badge/ubuntu-orange?style=for-the-badge&logo=ubuntu&logoColor=white)

üìñ:
[Vis√£o Geral](#vis√£o-geral) |
[Como reproduzir](#como-reproduzir) |
[Decis√µes T√©cnicas](#decis√µes-t√©cnicas)

</div>


## Vis√£o Geral

<div align="justify">
O objetivo do trabalho, realizado na disciplina de Intelig√™ncia Artificial ofertada pelo professor Tiago Aves de Oliveira, foi de compreender, implementar e comparar algoritmos cl√°ssicos de IA e Computa√ß√£o Natural, preparando e analisando dados reais.
</div>

### Partes do trabalho:
O trabalho foi dividido em quatro partes:

- Parte 1 - √Årvore de decis√£o manual
- Parte 2 - Supervisionado (Kaggle/UCI): KNN, SVM e √Årvore 
- Parte 3 - Algoritmo Gen√©tico (AG)
- Parte 4 - Enxame e Imunes

<!--
### Estrutura do Reposit√≥rio:
```
TRABALHO PR√ÅTICO IA/
‚îÇ   .gitattributes
‚îÇ   README.md
‚îÇ   requirements.txt
‚îÇ   svm.model
‚îÇ   
‚îú‚îÄ‚îÄ‚îÄdata
‚îÇ   ‚îú‚îÄ‚îÄ‚îÄprocessed
‚îÇ   ‚îÇ       benchmark_results.csv
‚îÇ   ‚îÇ       comparison_report.txt
‚îÇ   ‚îÇ       confusion_matrix_dt_100000.png
‚îÇ   ‚îÇ       confusion_matrix_knn_100000.png
‚îÇ   ‚îÇ       confusion_matrix_svm_100000.png
‚îÇ   ‚îÇ       decision_tree_visualization.png
‚îÇ   ‚îÇ       decision_tree_visualization_100000.png
‚îÇ   ‚îÇ       X_test.csv
‚îÇ   ‚îÇ       X_test_scaled.csv
‚îÇ   ‚îÇ       X_train.csv
‚îÇ   ‚îÇ       X_train_scaled.csv
‚îÇ   ‚îÇ       y_test.csv
‚îÇ   ‚îÇ       y_train.csv
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄraw
‚îÇ           Watera.csv
‚îÇ
‚îî‚îÄ‚îÄ‚îÄsrc
    ‚îú‚îÄ‚îÄ‚îÄpart1_tree_manual
    ‚îÇ       tree_diagram.md
    ‚îÇ       tree_image.png
    ‚îÇ       tree_manual.py
    ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄpart2_ml
    ‚îÇ   ‚îÇ   preprocess.py
    ‚îÇ   ‚îÇ   train_knn.py
    ‚îÇ   ‚îÇ   train_svm.py
    ‚îÇ   ‚îÇ   train_tree.py
    ‚îÇ   ‚îÇ   util_metrics.py
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ__pycache__
    ‚îÇ           preprocess.cpython-310.pyc
    ‚îÇ           preprocess.cpython-311.pyc
    ‚îÇ           util_metrics.cpython-310.pyc
    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄpart3_ga
            ga.py
```
-->
<!--
```
TREE-DECISION/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                    # Dados brutos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ plant_growth_data.csv
‚îÇ   ‚îî‚îÄ‚îÄ processed/              # Dados processados
‚îÇ       ‚îú‚îÄ‚îÄ X_train.csv         # Features de treino (sem escalonamento)
‚îÇ       ‚îú‚îÄ‚îÄ X_train_scaled.csv  # Features de treino (escalonadas)
‚îÇ       ‚îú‚îÄ‚îÄ y_train.csv         # Target de treino
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ part1_tree_manual/      # Implementa√ß√£o manual
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tree_manual.py      # Classe Tree customizada [Exemplo: 32 correntes filos√≥ficas]
‚îÇ   ‚îÇ   
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ part2_ml/               # Machine Learning
‚îÇ       ‚îú‚îÄ‚îÄ preprocess.py       # Pr√©-processamento completo
‚îÇ       ‚îú‚îÄ‚îÄ train_tree.py       # Treinar Decision Tree
‚îÇ       ‚îú‚îÄ‚îÄ train_knn.py        # Treinar KNN
‚îÇ       ‚îú‚îÄ‚îÄ train_svm.py        # Treinar SVM
‚îÇ       ‚îî‚îÄ‚îÄ util_metrics.py     # Fun√ß√µes de m√©tricas
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt            # Depend√™ncias
‚îî‚îÄ‚îÄ README.md                   # Este arquivo
```
-->

<!--
Este projeto explora **√Årvores de Decis√£o** de duas formas:

1. **Parte 1 - Implementa√ß√£o Manual (`src/part1_tree_manual/`)**
   - Estrutura de dados de √°rvore bin√°ria do zero
   - Visualiza√ß√£o com NetworkX e Matplotlib
   - Exemplo: √Årvore de decis√£o filos√≥fica com 32 correntes (6 n√≠veis)

2. **Parte 2 - Machine Learning (`src/part2_ml/`)**
   - Pr√©-processamento robusto de dados
   - Treinamento de modelos: Decision Tree, KNN, SVM
   - M√©tricas de avalia√ß√£o e valida√ß√£o cruzada 
-->



## Como reproduzir

### Pr√©-requisitos

- **Python 3.8+** instalado
- **pip** (gerenciador de pacotes Python)
- **Git** (opcional, para clonar o reposit√≥rio)

---

### Instala√ß√£o R√°pida

#### Usando run.sh (Linux):
```bash
# Concede permiss√µes de execu√ß√£o:
chmod +x run.sh

# Cria .venv e baixa depen√™ncias nele:
./run.sh
```

#### Usando Makefile (Alternativa):

```bash
# Instalar depend√™ncias
make install

# Executar Parte 1 (√Årvore Manual Filos√≥fica)
make part1

# Executar Parte 2 completa (ML: pr√©-processamento + treinos)
make part2

# Ou executar partes espec√≠ficas:
make part2-dt         # Apenas Decision Tree
make part2-knn        # Apenas KNN
make part2-svm        # Apenas SVM

# Executar Parte 3 (Algoritmo Gen√©tico)
make part3

# Ver resultados
make results

# Limpar arquivos gerados
make clean
```

#### Instala√ß√£o Manual

```bash
pip install -r requirements.txt
```

---

### Bibliotecas Utilizadas

| Biblioteca | Vers√£o | Por Que Usamos? | Decis√£o de Implementa√ß√£o |
|------------|--------|-----------------|--------------------------|
| **pandas** | 2.1.4 | Manipula√ß√£o de dados tabulares (CSV, DataFrames) | Escolhido por sua efici√™ncia em opera√ß√µes de leitura/escrita de CSV e transforma√ß√µes de dados. A API intuitiva permite opera√ß√µes complexas em uma linha. |
| **numpy** | 1.26.3 | Opera√ß√µes num√©ricas eficientes (arrays, matrizes) | Base para computa√ß√£o cient√≠fica em Python. Vetoriza√ß√£o de opera√ß√µes acelera c√°lculos em 10-100x comparado a loops Python puros. |
| **scikit-learn** | 1.3.2 | **Biblioteca principal de ML**: Decision Tree, KNN, SVM, pr√©-processamento, m√©tricas | API consistente entre algoritmos facilita experimenta√ß√£o. Implementa√ß√µes otimizadas em C/Cython garantem performance. Amplamente testada e documentada. |
| **scipy** | 1.11.4 | Algoritmos cient√≠ficos e estat√≠sticos (depend√™ncia do scikit-learn) | Fornece estruturas de dados especializadas (sparse matrices) e algoritmos de otimiza√ß√£o usados internamente pelo scikit-learn. |
| **matplotlib** | 3.8.2 | Visualiza√ß√£o de dados (gr√°ficos, plots) | Padr√£o *de facto* para visualiza√ß√£o cient√≠fica em Python. Flexibilidade para customiza√ß√£o detalhada de gr√°ficos. |
| **seaborn** | 0.13.0 | Visualiza√ß√£o estat√≠stica (matriz de confus√£o) | Built on top do matplotlib, oferece temas visuais mais modernos e fun√ß√µes especializadas para an√°lise estat√≠stica. |

---

<!--
### Sobre a escolha de cada Biblioteca

#### **scikit-learn** 
```python
# Modelos de ML
from sklearn.tree import DecisionTreeClassifier       # √Årvore de Decis√£o
from sklearn.neighbors import KNeighborsClassifier    # KNN
from sklearn.svm import SVC                           # SVM

# Pr√©-processamento
from sklearn.preprocessing import StandardScaler      # Escalonamento (KNN/SVM)
from sklearn.preprocessing import LabelEncoder        # String ‚Üí N√∫mero

# M√©tricas e Valida√ß√£o
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.model_selection import train_test_split, cross_val_score
```

#### **pandas** + **numpy**
```python
import pandas as pd    # Ler CSV, manipular tabelas
import numpy as np     # Opera√ß√µes matem√°ticas r√°pidas
```
-->

## Decis√µes T√©cnicas

### **Parte 1: √Årvore Manual (Filos√≥fica)**

#### Execu√ß√£o

```bash
make part1
```

#### O que faz
- Sistema interativo com 6 n√≠veis de perguntas filos√≥ficas
- Identifica 32 correntes filos√≥ficas diferentes
- Recomenda√ß√µes de livros personalizadas (200+ obras catalogadas)

#### Decis√µes de Implementa√ß√£o

**1. Estrutura de Dados Customizada**
```python
class Tree:
    def __init__(self, question, left=None, right=None, leaf_value=None):
        self.question = question
        self.left = left
        self.right = right
        self.leaf_value = leaf_value
```
- **Por que classe pr√≥pria?** Controle total sobre a l√≥gica de navega√ß√£o e visualiza√ß√£o. Permite adicionar m√©todos customizados (ex: `collect_all_nodes()`, `get_depth()`).
- **Alternativa considerada:** Usar `sklearn.tree.DecisionTreeClassifier`, mas n√£o permite constru√ß√£o manual da √°rvore com perguntas textuais.

**2. Hierarquia de 6 N√≠veis**
```
N√≠vel 1: Conhecimento (Racionalismo vs Empirismo)
N√≠vel 2: Realidade (Materialismo vs Idealismo)
N√≠vel 3: √âtica (Deontologia vs Consequencialismo)
N√≠vel 4: Exist√™ncia (Determinismo vs Livre-arb√≠trio)
N√≠vel 5: Pol√≠tica (Individualismo vs Coletivismo)
N√≠vel 6: Est√©tica (Objetividade vs Subjetividade)
```
- **Por que 6 n√≠veis?** 2^6 = 64 folhas poss√≠veis, mas usamos 32 correntes (algumas folhas compartilham ramos). Profundidade equilibra especificidade com usabilidade.
- **Decis√£o de design:** Ordem das perguntas segue progress√£o l√≥gica (fundamentos ‚Üí aplica√ß√µes pr√°ticas).


---

### **Parte 2: Machine Learning (Supervisionado)**

#### Execu√ß√£o Completa

```bash
# Execu√ß√£o de todas os algoritmos:
make part2

# Execu√ß√£o individual dos algoritmos:
make part2-preprocess
make part2-dt
make part2-knn
make part2-svm
```

---

#### **1. Pr√©-processamento (`preprocess.py`)**

##### Decis√µes de Implementa√ß√£o

**A. Tratamento de Valores Nulos**
```python
# Num√©ricos: Mediana (n√£o m√©dia!)
imputer_num = SimpleImputer(strategy='median')
X[numerical_cols] = imputer_num.fit_transform(X[numerical_cols])

# Categ√≥ricos: Moda
imputer_cat = SimpleImputer(strategy='most_frequent')
X[categorical_cols] = imputer_cat.fit_transform(X[categorical_cols])
```
- **Por que mediana e n√£o m√©dia?** 
  - M√©dia √© sens√≠vel a outliers. Se 99 valores s√£o ~10 e 1 valor √© 10.000, a m√©dia ser√° distorcida.
  - Mediana √© robusta: sempre retorna o valor central.
  - **Exemplo real:** Em dados de qualidade de √°gua, um sensor defeituoso pode gerar pH=999. Mediana ignora esse erro.

**B. Label Encoding vs One-Hot Encoding**
```python
# Label Encoding (usado no projeto)
le = LabelEncoder()
X['Soil_Type'] = le.fit_transform(X['Soil_Type'])
# ['loam', 'sandy', 'clay'] ‚Üí [0, 1, 2]

# One-Hot Encoding (comentado, mas dispon√≠vel)
X_encoded = pd.get_dummies(X, columns=['Soil_Type'], drop_first=True)
# Soil_Type_loam | Soil_Type_sandy | Soil_Type_clay
#       1        |        0        |       0
```
- **Por que Label Encoding?**
  - **Decision Trees:** N√£o precisam de One-Hot. √Årvores podem lidar com ordinais (0, 1, 2) diretamente.
  - **KNN/SVM:** Label Encoding funciona quando h√° ordem natural (ex: Pequeno=0, M√©dio=1, Grande=2).
  - **Quando usar One-Hot:** Categorias sem ordem (ex: cores: vermelho, azul, verde). Evita o modelo assumir que "azul" (1) est√° "entre" vermelho (0) e verde (2).
- **Trade-off:** One-Hot aumenta dimensionalidade. 10 categorias ‚Üí 10 colunas. Afeta performance em datasets grandes.

**C. Escalonamento: StandardScaler vs MinMaxScaler**
```python
# StandardScaler (m√©dia=0, desvio=1)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# MinMaxScaler (valores entre 0 e 1) - usado no projeto
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)
```
- **Por que MinMaxScaler?**
  - **KNN:** Dist√¢ncias euclidianas s√£o afetadas por escala. Feature "Renda" (0-100k) dominaria "Idade" (0-100).
  - **SVM:** Kernel RBF usa dist√¢ncias. Features com ranges diferentes quebram a simetria do kernel.
  - **MinMaxScaler vs StandardScaler:** 
    - MinMaxScaler preserva distribui√ß√£o original (boa para dados sem outliers extremos).
    - StandardScaler melhor quando h√° outliers (normaliza pelo desvio padr√£o).
  - **Decision Trees N√ÉO precisam:** √Årvores fazem splits baseados em thresholds relativos (ex: "pH > 7?"). Escala n√£o importa.

**D. Divis√£o Estratificada**
```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2, 
    stratify=y,  # CRUCIAL!
    random_state=42
)
```
- **Por que estratifica√ß√£o?**
  - **Problema:** Dataset com 90% classe A, 10% classe B. Split aleat√≥rio pode gerar treino com 95% A, teste com 85% A.
  - **Solu√ß√£o:** `stratify=y` garante que treino E teste tenham 90% A, 10% B.
  - **Impacto:** Sem estratifica√ß√£o, m√©tricas podem ser enviesadas. Modelo "aprende" distribui√ß√£o diferente da realidade.

**E. Amostragem Aleat√≥ria (10k, 50k, 100k)**
```python
df_sample = df.sample(n=sample_size, random_state=42)
```
- **Por que amostrar?**
  - **Benchmarking:** Comparar performance dos algoritmos em diferentes escalas de dados.
  - **Trade-off tempo vs acur√°cia:** SVM com 100k linhas pode levar horas. 10k linhas permite itera√ß√£o r√°pida.
  - **`random_state=42`:** Reprodutibilidade. Mesma amostra em execu√ß√µes diferentes.

---

#### **2. Treinamento dos Modelos**

##### **Decision Tree (`train_tree.py`)**

```python
dt = DecisionTreeClassifier(
    max_depth=10,              # Limita profundidade
    min_samples_split=20,      # M√≠nimo de amostras para split
    min_samples_leaf=10,       # M√≠nimo de amostras por folha
    random_state=42
)
```

**Decis√µes de Hiperpar√¢metros:**

| Par√¢metro | Valor | Por Que? | Risco se Diferente |
|-----------|-------|----------|-------------------|
| `max_depth=10` | 10 n√≠veis | Profundidade m√©dia para datasets tabulares. Previne overfitting em dados com ru√≠do. | **Muito alto (ex: 50):** √Årvore memoriza treino (overfitting). **Muito baixo (ex: 3):** Underfitting, n√£o captura padr√µes. |
| `min_samples_split=20` | 20 amostras | Evita splits em subconjuntos pequenos (pouco representativos). | **Muito baixo (ex: 2):** √Årvore cria regras espec√≠ficas para poucos exemplos (overfitting). |
| `min_samples_leaf=10` | 10 amostras | Garante que folhas tenham exemplos suficientes para generalizar. | **Muito baixo (ex: 1):** Folhas com 1 exemplo = decorar dataset. |

**Por que Decision Trees s√£o robustas:**
- **N√£o precisam de escalonamento:** Splits baseados em thresholds (ex: "Temperatura > 25¬∞C?").
- **Lidam com n√£o-linearidade:** Capturam intera√ß√µes complexas (ex: "SE temperatura > 30 E umidade < 40 ENT√ÉO...").
- **Interpretabilidade:** Regras leg√≠veis por humanos.
- **Overfitting f√°cil:** Sem regulariza√ß√£o, decoram o treino. Por isso os hiperpar√¢metros acima.

---

##### **KNN (`train_knn.py`)**

```python
knn = KNeighborsClassifier(
    n_neighbors=5,    # K=5 vizinhos
    n_jobs=-1         # Paraleliza√ß√£o (usa todos os cores)
)
```

**Sele√ß√£o do K=5:**
```python
# Testamos K de 1 a 20 e plotamos acur√°cia
k_range = list(range(1, 21))
for k in k_range:
    knn = KNeighborsClassifier(n_neighbors=k)
    # ... treinar e avaliar
# Gr√°fico mostra K=5 como melhor trade-off
```

| K | Comportamento | Por Que N√£o Escolher? |
|---|---------------|----------------------|
| **K=1** | Classifica baseado no vizinho mais pr√≥ximo | **Overfitting:** Sens√≠vel a ru√≠do. Um outlier mislabeled pode quebrar predi√ß√£o. |
| **K=5** | **Balanceado** | Suaviza ru√≠do sem perder granularidade. |
| **K=20** | Classifica baseado em 20 vizinhos | **Underfitting:** Fronteiras de decis√£o muito suaves. Perde detalhes. |

---

##### **SVM (`train_svm.py`)**

```python
svm = SVC(
    kernel='rbf',        # Radial Basis Function (n√£o-linear)
    C=1.0,               # Regulariza√ß√£o
    probability=True,    # Habilita predict_proba() para ROC-AUC
    random_state=42
)
```

**Decis√µes de Hiperpar√¢metros:**

| Par√¢metro | Valor | Por Que? |
|-----------|-------|----------|
| `kernel='rbf'` | Radial Basis Function | **N√£o-linear:** Mapeia dados para espa√ßo de alta dimens√£o onde s√£o linearmente separ√°veis. Alternativas: `'linear'` (mais r√°pido, assume separabilidade linear), `'poly'` (polinomial, caro computacionalmente). |
| `C=1.0` | Penaliza√ß√£o padr√£o | **Trade-off:** C alto ‚Üí Margem estreita (overfitting). C baixo ‚Üí Margem larga (underfitting). 1.0 √© balanceado. |
| `probability=True` | Habilita probabilidades | **Necess√°rio para ROC-AUC:** `predict()` retorna classes (0, 1). `predict_proba()` retorna probabilidades (0.0-1.0). Aumenta tempo de treino (~2x), mas essencial para m√©tricas. |

**PCA Opcional (Redu√ß√£o de Dimensionalidade):**
```python
if use_pca:
    pca = PCA(n_components=2)  # Reduz para 2 dimens√µes
    X_train_pca = pca.fit_transform(X_train_scaled)
```
- **Por que PCA?** SVM √© O(n¬≤ a n¬≥) em n√∫mero de amostras. Com muitas features, treino fica lento. PCA reduz features mantendo vari√¢ncia.
- **Trade-off:** Perda de informa√ß√£o. 2 componentes podem capturar 80% da vari√¢ncia, mas 20% √© perdido.

---

#### **3. M√©tricas de Avalia√ß√£o (`util_metrics.py`)**

```python
metrics = {
    'accuracy': accuracy_score(y_true, y_pred),
    'precision': precision_score(y_true, y_pred, average='macro'),
    'recall': recall_score(y_true, y_pred, average='macro'),
    'f1_score': f1_score(y_true, y_pred, average='macro'),
    'roc_auc': roc_auc_score(y_true, y_prob, multi_class='ovr', average='macro')
}
```

**Por que m√∫ltiplas m√©tricas?**

| M√©trica | O que mede | Quando usar |
|---------|------------|-------------|
| **Acur√°cia** | % de predi√ß√µes corretas | Classes balanceadas. **Cuidado:** 90% acur√°cia em dataset com 90% classe A = modelo in√∫til (prediz sempre A). |
| **Precis√£o** | % de positivos previstos que s√£o realmente positivos | Falsos positivos s√£o caros. Ex: spam (marcar email leg√≠timo como spam). |
| **Recall** | % de positivos reais que foram identificados | Falsos negativos s√£o caros. Ex: diagn√≥stico de c√¢ncer (n√£o detectar doen√ßa). |
| **F1-Score** | M√©dia harm√¥nica de Precis√£o e Recall | Trade-off entre FP e FN. Classes desbalanceadas. |
| **ROC-AUC** | √Årea sob curva ROC (varia de 0 a 1) | Avalia performance em diferentes thresholds. 1.0 = perfeito, 0.5 = aleat√≥rio. |


---


### **Parte 3: Algoritmo Gen√©tico**

#### Execu√ß√£o no terminal:
```bash
make part3
```

#### Decis√µes de implementa√ß√£o:
- **Problema implementado:** Knapsack 0/1 (Problema da Mochila);
- Foi utilizada a semente aleat√≥ria `random.seed(42)` para padronizar a gera√ß√£o de itens;
- A codifica√ß√£o na gera√ß√£o de itens foi feita em uma lista de tuplas, em que o primeiro n√∫mero da tupla armazena o peso do item e o segundo n√∫mero armazena o valor do item (_fitness_). Isso tamb√©m √© imprimido no terminal da seguinte forma:
```
[(1, 1), (3, 4), (2, 3), (1, 2), (5, 7), (1, 1), (1, 4), (2, 1), (5, 4), (5, 7)] 
```

- A codifica√ß√£o dos genes √© feita de forma bin√°ria, com base no √≠ndice da lista de itens do problema. No caso, um gene √© uma lista do tamanho do n√∫mero de itens, em que 1 indica que o item foi selecionado para entrar na mochila e 0 indica que o item n√£o foi selecionado, como pode ser visto a seguir:

```
[1, 0, 0, 0, 0, 0, 0, 0, 0, 1]
```

- O problema foi parametrizado com base nos seguintes par√¢metros e valores padr√£o para execu√ß√£o:

| Par√¢metros | Valores |
|------------|---------|
| N√∫mero de itens | 10 |
| Peso m√°ximo por item | 5 |
| Valor m√°ximo por item | 8 |
| Peso m√°ximo da mochila | 10 |
| Tamanho da popula√ß√£o | 400 |
| N√∫mero de gera√ß√µes | 1000 |
| Taxa inicial de muta√ß√£o | 1% |
| Taxa vari√°vel de muta√ß√£o | 5% | 

- O fitness de um gene √© calculado com base na soma dos valores dos itens no gene quando a soma dos pesos dos itens do gene √© menor ou
igual ao limite de peso da mochila. Caso contr√°rio, o fitness √© zerado.

- A implementa√ß√£o conta com operadores caracter√≠sticos do algoritmo gen√©tico:
  - _Elitismo:_ Permite no c√≥digo com que ma que os dois genes com maior fitness de
  uma gera√ß√£o sejam preservados para a pr√≥xima gera√ß√£o, desde que ambos possuam fitness maior que zero.
  - _Sele√ß√£o de Pais por roleta:_ Cada gene recebe uma porcentagem com base em seu fitness, que dita a chance de que ele se torne pai atrav√©s da roleta viciada (sem contar com o elitismo).
  - _Taxa de muta√ß√£o vari√°vel:_ Ap√≥s 50 gera√ß√µes, a taxa de muta√ß√£o sobe de 1% para 5%, a fim de garantir movimenta√ß√µes bem-vindas na diversidade gen√©tica dos genes dispon√≠veis ap√≥s esse momento.

## Resultados e Compara√ß√µes

### Visualizar Resultados

```bash
make results
```

Este comando exibe:
- **Relat√≥rio comparativo** (`comparison_report.txt`) com m√©tricas de todos os algoritmos
- **Benchmark CSV** (`benchmark_results.csv`) com dados tabulares
- **Matrizes de confus√£o** (`.png`) para an√°lise visual de erros
- **Gr√°fico de sele√ß√£o de K** (KNN) mostrando por que K=5 foi escolhido
- **Visualiza√ß√£o da Decision Tree** (estrutura completa da √°rvore)

### Interpreta√ß√£o dos Resultados

**Compara√ß√£o T√≠pica (Water Quality Dataset):**

| Algoritmo | Acur√°cia Teste | Tempo Treino | Overfitting | Interpretabilidade |
|-----------|----------------|--------------|-------------|-------------------|
| **Decision Tree** | ~98.7% | ~0.45s | Baixo (0.008%) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **KNN** | ~92.6% | ~0.23s | M√©dio (2.8%) | ‚≠ê‚≠ê |
| **SVM** | ~95.0% | ~590s | Baixo (-0.07%) | ‚≠ê |

**An√°lise:**
- **Decision Tree:** Melhor acur√°cia e interpretabilidade. R√°pida de treinar. **Escolha ideal para este dataset.**
- **KNN:** Treino r√°pido, mas performance inferior. Overfitting moderado (decora padr√µes locais do treino).
- **SVM:** Boa acur√°cia, mas treino MUITO lento (10 minutos para 100k linhas). Modelo "black box" (dif√≠cil interpretar).

**Por que Decision Tree venceu aqui?**
1. **Dataset tabular com features num√©ricas:** √Årvores s√£o naturalmente adequadas para dados estruturados.
2. **Intera√ß√µes n√£o-lineares:** √Ågua pot√°vel depende de combina√ß√µes (ex: pH alto + Cloro baixo = n√£o pot√°vel).
3. **Dados limpos:** Poucas outliers extremas, ent√£o robustez do KNN n√£o foi necess√°ria.
4. **Interpretabilidade requerida:** Podemos extrair regras (ex: "SE Hardness < 200 E Solids > 20000 ENT√ÉO pot√°vel").

---

## Estrutura de Arquivos Gerados

```
data/processed/
‚îú‚îÄ‚îÄ benchmark_results.csv           # M√©tricas de todos os treinos
‚îú‚îÄ‚îÄ comparison_report.txt           # Relat√≥rio formatado
‚îú‚îÄ‚îÄ confusion_matrix_dt_100000.png  # Matriz de confus√£o (Decision Tree)
‚îú‚îÄ‚îÄ confusion_matrix_knn_100000.png # Matriz de confus√£o (KNN)
‚îú‚îÄ‚îÄ confusion_matrix_svm_100000.png # Matriz de confus√£o (SVM)
‚îú‚îÄ‚îÄ decision_tree_visualization_100000.png  # √Årvore completa
‚îú‚îÄ‚îÄ knn_k_selection.png             # Gr√°fico de sele√ß√£o de K
‚îú‚îÄ‚îÄ X_train.csv                     # Features de treino (n√£o escalonadas)
‚îú‚îÄ‚îÄ X_train_scaled.csv              # Features de treino (escalonadas)
‚îú‚îÄ‚îÄ X_test.csv                      # Features de teste (n√£o escalonadas)
‚îú‚îÄ‚îÄ X_test_scaled.csv               # Features de teste (escalonadas)
‚îú‚îÄ‚îÄ y_train.csv                     # Labels de treino
‚îî‚îÄ‚îÄ y_test.csv                      # Labels de teste
```


---

## Refer√™ncias 

- **"Introduction to Machine Learning with Python"** - Andreas M√ºller & Sarah Guido
  - Cap√≠tulos 2-3: Pr√©-processamento e valida√ß√£o
  - Cap√≠tulo 5: Decision Trees, KNN, SVM
- **"Hands-On Machine Learning"** - Aur√©lien G√©ron
  - Cap√≠tulo 6: Decision Trees e Random Forests
  - Cap√≠tulo 5: SVM e Kernel Trick

### Documenta√ß√£o Oficial
- [scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [pandas Documentation](https://pandas.pydata.org/docs/)

---

## Licen√ßa e Autoria

**Disciplina:** Intelig√™ncia Artificial (2025/2)  
**Professor:** Tiago Alves de Oliveira  
**Institui√ß√£o:** Cefet-MG Divin√≥polis
**Alunos:** Jo√£o Pedro Rodrigues Silva e Samuel Silva Gomes

---

## Contato

Para d√∫vidas ou sugest√µes, abra uma issue no reposit√≥rio ou entre em contato com os autores.

