<h1 align="center">Trabalho PrÃ¡tico IA [Algoritmos] (2025/2)</h1>

<div align="center">

![Python](https://img.shields.io/badge/python-blue?style=for-the-badge&logo=python&logoColor=white)
![VS Code](https://img.shields.io/badge/visual%20studio%20code-blue?style=for-the-badge)
![Ubuntu](https://img.shields.io/badge/ubuntu-orange?style=for-the-badge&logo=ubuntu&logoColor=white)

ğŸ“–:
[VisÃ£o Geral](#visÃ£o-geral) |
[Como reproduzir](#como-reproduzir) |
[DecisÃµes TÃ©cnicas](#decisÃµes-tÃ©cnicas)

</div>


## VisÃ£o Geral

<div align="justify">
O objetivo do trabalho, realizado na disciplina de InteligÃªncia Artificial ofertada pelo professor Tiago Aves de Oliveira, foi de compreender, implementar e comparar algoritmos clÃ¡ssicos de IA e ComputaÃ§Ã£o Natural, preparando e analisando dados reais.
</div>

### Partes do trabalho:
O trabalho foi dividido em quatro partes:

- Parte 1 - Ãrvore de decisÃ£o manual
- Parte 2 - Supervisionado (Kaggle/UCI): KNN, SVM e Ãrvore 
- Parte 3 - Algoritmo GenÃ©tico (AG)
- Parte 4 - Enxame e Imunes

### Estrutura do RepositÃ³rio:
```
TRABALHO PRÃTICO IA/
â”‚   .gitattributes
â”‚   README.md
â”‚   requirements.txt
â”‚   svm.model
â”‚   
â”œâ”€â”€â”€data
â”‚   â”œâ”€â”€â”€processed
â”‚   â”‚       benchmark_results.csv
â”‚   â”‚       comparison_report.txt
â”‚   â”‚       confusion_matrix_dt_100000.png
â”‚   â”‚       confusion_matrix_knn_100000.png
â”‚   â”‚       confusion_matrix_svm_100000.png
â”‚   â”‚       decision_tree_visualization.png
â”‚   â”‚       decision_tree_visualization_100000.png
â”‚   â”‚       X_test.csv
â”‚   â”‚       X_test_scaled.csv
â”‚   â”‚       X_train.csv
â”‚   â”‚       X_train_scaled.csv
â”‚   â”‚       y_test.csv
â”‚   â”‚       y_train.csv
â”‚   â”‚
â”‚   â””â”€â”€â”€raw
â”‚           Watera.csv
â”‚
â””â”€â”€â”€src
    â”œâ”€â”€â”€part1_tree_manual
    â”‚       tree_diagram.md
    â”‚       tree_image.png
    â”‚       tree_manual.py
    â”‚
    â”œâ”€â”€â”€part2_ml
    â”‚   â”‚   preprocess.py
    â”‚   â”‚   train_knn.py
    â”‚   â”‚   train_svm.py
    â”‚   â”‚   train_tree.py
    â”‚   â”‚   util_metrics.py
    â”‚   â”‚
    â”‚   â””â”€â”€â”€__pycache__
    â”‚           preprocess.cpython-310.pyc
    â”‚           preprocess.cpython-311.pyc
    â”‚           util_metrics.cpython-310.pyc
    â”‚
    â””â”€â”€â”€part3_ga
            ga.py
```

<!--
```
TREE-DECISION/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Dados brutos
â”‚   â”‚   â””â”€â”€ plant_growth_data.csv
â”‚   â””â”€â”€ processed/              # Dados processados
â”‚       â”œâ”€â”€ X_train.csv         # Features de treino (sem escalonamento)
â”‚       â”œâ”€â”€ X_train_scaled.csv  # Features de treino (escalonadas)
â”‚       â”œâ”€â”€ y_train.csv         # Target de treino
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ part1_tree_manual/      # ImplementaÃ§Ã£o manual
â”‚   â”‚   â””â”€â”€ tree_manual.py      # Classe Tree customizada [Exemplo: 32 correntes filosÃ³ficas]
â”‚   â”‚   
â”‚   â”‚
â”‚   â””â”€â”€ part2_ml/               # Machine Learning
â”‚       â”œâ”€â”€ preprocess.py       # PrÃ©-processamento completo
â”‚       â”œâ”€â”€ train_tree.py       # Treinar Decision Tree
â”‚       â”œâ”€â”€ train_knn.py        # Treinar KNN
â”‚       â”œâ”€â”€ train_svm.py        # Treinar SVM
â”‚       â””â”€â”€ util_metrics.py     # FunÃ§Ãµes de mÃ©tricas
â”‚
â”œâ”€â”€ requirements.txt            # DependÃªncias
â””â”€â”€ README.md                   # Este arquivo
```
-->

<!--
Este projeto explora **Ãrvores de DecisÃ£o** de duas formas:

1. **Parte 1 - ImplementaÃ§Ã£o Manual (`src/part1_tree_manual/`)**
   - Estrutura de dados de Ã¡rvore binÃ¡ria do zero
   - VisualizaÃ§Ã£o com NetworkX e Matplotlib
   - Exemplo: Ãrvore de decisÃ£o filosÃ³fica com 32 correntes (6 nÃ­veis)

2. **Parte 2 - Machine Learning (`src/part2_ml/`)**
   - PrÃ©-processamento robusto de dados
   - Treinamento de modelos: Decision Tree, KNN, SVM
   - MÃ©tricas de avaliaÃ§Ã£o e validaÃ§Ã£o cruzada 
-->



## Como reproduzir

### PrÃ©-requisitos

- **Python 3.8+** instalado
- **pip** (gerenciador de pacotes Python)
- **Git** (opcional, para clonar o repositÃ³rio)

---

### InstalaÃ§Ã£o RÃ¡pida

#### Usando run.sh (Linux):
```bash
# Concede permissÃµes de execuÃ§Ã£o:
chmod +x run.sh

# Cria .venv e baixa depenÃªncias nele:
./run.sh
```

#### Usando Makefile (Alternativa):

```bash
# Instalar dependÃªncias
make install

# Executar Parte 1 (Ãrvore Manual FilosÃ³fica)
make part1

# Executar Parte 2 completa (ML: prÃ©-processamento + treinos)
make part2

# Ou executar partes especÃ­ficas:
make part2-dt         # Apenas Decision Tree
make part2-knn        # Apenas KNN
make part2-svm        # Apenas SVM

# Executar Parte 3 (Algoritmo GenÃ©tico)
make part3

# Ver resultados
make results

# Limpar arquivos gerados
make clean
```

#### InstalaÃ§Ã£o Manual

```bash
pip install -r requirements.txt
```

---

### Bibliotecas Utilizadas

| Biblioteca | VersÃ£o | Por Que Usamos? | DecisÃ£o de ImplementaÃ§Ã£o |
|------------|--------|-----------------|--------------------------|
| **pandas** | 2.1.4 | ManipulaÃ§Ã£o de dados tabulares (CSV, DataFrames) | Escolhido por sua eficiÃªncia em operaÃ§Ãµes de leitura/escrita de CSV e transformaÃ§Ãµes de dados. A API intuitiva permite operaÃ§Ãµes complexas em uma linha. |
| **numpy** | 1.26.3 | OperaÃ§Ãµes numÃ©ricas eficientes (arrays, matrizes) | Base para computaÃ§Ã£o cientÃ­fica em Python. VetorizaÃ§Ã£o de operaÃ§Ãµes acelera cÃ¡lculos em 10-100x comparado a loops Python puros. |
| **scikit-learn** | 1.3.2 | **Biblioteca principal de ML**: Decision Tree, KNN, SVM, prÃ©-processamento, mÃ©tricas | API consistente entre algoritmos facilita experimentaÃ§Ã£o. ImplementaÃ§Ãµes otimizadas em C/Cython garantem performance. Amplamente testada e documentada. |
| **scipy** | 1.11.4 | Algoritmos cientÃ­ficos e estatÃ­sticos (dependÃªncia do scikit-learn) | Fornece estruturas de dados especializadas (sparse matrices) e algoritmos de otimizaÃ§Ã£o usados internamente pelo scikit-learn. |
| **matplotlib** | 3.8.2 | VisualizaÃ§Ã£o de dados (grÃ¡ficos, plots) | PadrÃ£o *de facto* para visualizaÃ§Ã£o cientÃ­fica em Python. Flexibilidade para customizaÃ§Ã£o detalhada de grÃ¡ficos. |
| **seaborn** | 0.13.0 | VisualizaÃ§Ã£o estatÃ­stica (matriz de confusÃ£o) | Built on top do matplotlib, oferece temas visuais mais modernos e funÃ§Ãµes especializadas para anÃ¡lise estatÃ­stica. |

---

<!--
### Sobre a escolha de cada Biblioteca

#### **scikit-learn** 
```python
# Modelos de ML
from sklearn.tree import DecisionTreeClassifier       # Ãrvore de DecisÃ£o
from sklearn.neighbors import KNeighborsClassifier    # KNN
from sklearn.svm import SVC                           # SVM

# PrÃ©-processamento
from sklearn.preprocessing import StandardScaler      # Escalonamento (KNN/SVM)
from sklearn.preprocessing import LabelEncoder        # String â†’ NÃºmero

# MÃ©tricas e ValidaÃ§Ã£o
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.model_selection import train_test_split, cross_val_score
```

#### **pandas** + **numpy**
```python
import pandas as pd    # Ler CSV, manipular tabelas
import numpy as np     # OperaÃ§Ãµes matemÃ¡ticas rÃ¡pidas
```
-->

## DecisÃµes TÃ©cnicas

### **Parte 1: Ãrvore Manual (FilosÃ³fica)**

#### ExecuÃ§Ã£o

```bash
make part1
```

#### O que faz
- Sistema interativo com 6 nÃ­veis de perguntas filosÃ³ficas
- Identifica 32 correntes filosÃ³ficas diferentes
- RecomendaÃ§Ãµes de livros personalizadas (200+ obras catalogadas)

#### DecisÃµes de ImplementaÃ§Ã£o

**1. Estrutura de Dados Customizada**
```python
class Tree:
    def __init__(self, question, left=None, right=None, leaf_value=None):
        self.question = question
        self.left = left
        self.right = right
        self.leaf_value = leaf_value
```
- **Por que classe prÃ³pria?** Controle total sobre a lÃ³gica de navegaÃ§Ã£o e visualizaÃ§Ã£o. Permite adicionar mÃ©todos customizados (ex: `collect_all_nodes()`, `get_depth()`).
- **Alternativa considerada:** Usar `sklearn.tree.DecisionTreeClassifier`, mas nÃ£o permite construÃ§Ã£o manual da Ã¡rvore com perguntas textuais.

**2. Hierarquia de 6 NÃ­veis**
```
NÃ­vel 1: Conhecimento (Racionalismo vs Empirismo)
NÃ­vel 2: Realidade (Materialismo vs Idealismo)
NÃ­vel 3: Ã‰tica (Deontologia vs Consequencialismo)
NÃ­vel 4: ExistÃªncia (Determinismo vs Livre-arbÃ­trio)
NÃ­vel 5: PolÃ­tica (Individualismo vs Coletivismo)
NÃ­vel 6: EstÃ©tica (Objetividade vs Subjetividade)
```
- **Por que 6 nÃ­veis?** 2^6 = 64 folhas possÃ­veis, mas usamos 32 correntes (algumas folhas compartilham ramos). Profundidade equilibra especificidade com usabilidade.
- **DecisÃ£o de design:** Ordem das perguntas segue progressÃ£o lÃ³gica (fundamentos â†’ aplicaÃ§Ãµes prÃ¡ticas).


---

### **Parte 2: Machine Learning (Supervisionado)**

#### ExecuÃ§Ã£o Completa

```bash
# ExecuÃ§Ã£o de todas os algoritmos:
make part2

# ExecuÃ§Ã£o individual dos algoritmos:
make part2-preprocess
make part2-dt
make part2-knn
make part2-svm
```

---

#### **1. PrÃ©-processamento (`preprocess.py`)**

##### DecisÃµes de ImplementaÃ§Ã£o

**A. Tratamento de Valores Nulos**
```python
# NumÃ©ricos: Mediana (nÃ£o mÃ©dia!)
imputer_num = SimpleImputer(strategy='median')
X[numerical_cols] = imputer_num.fit_transform(X[numerical_cols])

# CategÃ³ricos: Moda
imputer_cat = SimpleImputer(strategy='most_frequent')
X[categorical_cols] = imputer_cat.fit_transform(X[categorical_cols])
```
- **Por que mediana e nÃ£o mÃ©dia?** 
  - MÃ©dia Ã© sensÃ­vel a outliers. Se 99 valores sÃ£o ~10 e 1 valor Ã© 10.000, a mÃ©dia serÃ¡ distorcida.
  - Mediana Ã© robusta: sempre retorna o valor central.
  - **Exemplo real:** Em dados de qualidade de Ã¡gua, um sensor defeituoso pode gerar pH=999. Mediana ignora esse erro.

**B. Label Encoding vs One-Hot Encoding**
```python
# Label Encoding (usado no projeto)
le = LabelEncoder()
X['Soil_Type'] = le.fit_transform(X['Soil_Type'])
# ['loam', 'sandy', 'clay'] â†’ [0, 1, 2]

# One-Hot Encoding (comentado, mas disponÃ­vel)
X_encoded = pd.get_dummies(X, columns=['Soil_Type'], drop_first=True)
# Soil_Type_loam | Soil_Type_sandy | Soil_Type_clay
#       1        |        0        |       0
```
- **Por que Label Encoding?**
  - **Decision Trees:** NÃ£o precisam de One-Hot. Ãrvores podem lidar com ordinais (0, 1, 2) diretamente.
  - **KNN/SVM:** Label Encoding funciona quando hÃ¡ ordem natural (ex: Pequeno=0, MÃ©dio=1, Grande=2).
  - **Quando usar One-Hot:** Categorias sem ordem (ex: cores: vermelho, azul, verde). Evita o modelo assumir que "azul" (1) estÃ¡ "entre" vermelho (0) e verde (2).
- **Trade-off:** One-Hot aumenta dimensionalidade. 10 categorias â†’ 10 colunas. Afeta performance em datasets grandes.

**C. Escalonamento: StandardScaler vs MinMaxScaler**
```python
# StandardScaler (mÃ©dia=0, desvio=1)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# MinMaxScaler (valores entre 0 e 1) - usado no projeto
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)
```
- **Por que MinMaxScaler?**
  - **KNN:** DistÃ¢ncias euclidianas sÃ£o afetadas por escala. Feature "Renda" (0-100k) dominaria "Idade" (0-100).
  - **SVM:** Kernel RBF usa distÃ¢ncias. Features com ranges diferentes quebram a simetria do kernel.
  - **MinMaxScaler vs StandardScaler:** 
    - MinMaxScaler preserva distribuiÃ§Ã£o original (boa para dados sem outliers extremos).
    - StandardScaler melhor quando hÃ¡ outliers (normaliza pelo desvio padrÃ£o).
  - **Decision Trees NÃƒO precisam:** Ãrvores fazem splits baseados em thresholds relativos (ex: "pH > 7?"). Escala nÃ£o importa.

**D. DivisÃ£o Estratificada**
```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2, 
    stratify=y,  # CRUCIAL!
    random_state=42
)
```
- **Por que estratificaÃ§Ã£o?**
  - **Problema:** Dataset com 90% classe A, 10% classe B. Split aleatÃ³rio pode gerar treino com 95% A, teste com 85% A.
  - **SoluÃ§Ã£o:** `stratify=y` garante que treino E teste tenham 90% A, 10% B.
  - **Impacto:** Sem estratificaÃ§Ã£o, mÃ©tricas podem ser enviesadas. Modelo "aprende" distribuiÃ§Ã£o diferente da realidade.

**E. Amostragem AleatÃ³ria (10k, 50k, 100k)**
```python
df_sample = df.sample(n=sample_size, random_state=42)
```
- **Por que amostrar?**
  - **Benchmarking:** Comparar performance dos algoritmos em diferentes escalas de dados.
  - **Trade-off tempo vs acurÃ¡cia:** SVM com 100k linhas pode levar horas. 10k linhas permite iteraÃ§Ã£o rÃ¡pida.
  - **`random_state=42`:** Reprodutibilidade. Mesma amostra em execuÃ§Ãµes diferentes.

---

#### **2. Treinamento dos Modelos**

##### **Decision Tree (`train_tree.py`)**

```python
dt = DecisionTreeClassifier(
    max_depth=10,              # Limita profundidade
    min_samples_split=20,      # MÃ­nimo de amostras para split
    min_samples_leaf=10,       # MÃ­nimo de amostras por folha
    random_state=42
)
```

**DecisÃµes de HiperparÃ¢metros:**

| ParÃ¢metro | Valor | Por Que? | Risco se Diferente |
|-----------|-------|----------|-------------------|
| `max_depth=10` | 10 nÃ­veis | Profundidade mÃ©dia para datasets tabulares. Previne overfitting em dados com ruÃ­do. | **Muito alto (ex: 50):** Ãrvore memoriza treino (overfitting). **Muito baixo (ex: 3):** Underfitting, nÃ£o captura padrÃµes. |
| `min_samples_split=20` | 20 amostras | Evita splits em subconjuntos pequenos (pouco representativos). | **Muito baixo (ex: 2):** Ãrvore cria regras especÃ­ficas para poucos exemplos (overfitting). |
| `min_samples_leaf=10` | 10 amostras | Garante que folhas tenham exemplos suficientes para generalizar. | **Muito baixo (ex: 1):** Folhas com 1 exemplo = decorar dataset. |

**Por que Decision Trees sÃ£o robustas:**
- **NÃ£o precisam de escalonamento:** Splits baseados em thresholds (ex: "Temperatura > 25Â°C?").
- **Lidam com nÃ£o-linearidade:** Capturam interaÃ§Ãµes complexas (ex: "SE temperatura > 30 E umidade < 40 ENTÃƒO...").
- **Interpretabilidade:** Regras legÃ­veis por humanos.
- **Overfitting fÃ¡cil:** Sem regularizaÃ§Ã£o, decoram o treino. Por isso os hiperparÃ¢metros acima.

---

##### **KNN (`train_knn.py`)**

```python
knn = KNeighborsClassifier(
    n_neighbors=5,    # K=5 vizinhos
    n_jobs=-1         # ParalelizaÃ§Ã£o (usa todos os cores)
)
```

**SeleÃ§Ã£o do K=5:**
```python
# Testamos K de 1 a 20 e plotamos acurÃ¡cia
k_range = list(range(1, 21))
for k in k_range:
    knn = KNeighborsClassifier(n_neighbors=k)
    # ... treinar e avaliar
# GrÃ¡fico mostra K=5 como melhor trade-off
```

| K | Comportamento | Por Que NÃ£o Escolher? |
|---|---------------|----------------------|
| **K=1** | Classifica baseado no vizinho mais prÃ³ximo | **Overfitting:** SensÃ­vel a ruÃ­do. Um outlier mislabeled pode quebrar prediÃ§Ã£o. |
| **K=5** | **Balanceado** | Suaviza ruÃ­do sem perder granularidade. |
| **K=20** | Classifica baseado em 20 vizinhos | **Underfitting:** Fronteiras de decisÃ£o muito suaves. Perde detalhes. |

---

##### **SVM (`train_svm.py`)**

```python
svm = SVC(
    kernel='rbf',        # Radial Basis Function (nÃ£o-linear)
    C=1.0,               # RegularizaÃ§Ã£o
    probability=True,    # Habilita predict_proba() para ROC-AUC
    random_state=42
)
```

**DecisÃµes de HiperparÃ¢metros:**

| ParÃ¢metro | Valor | Por Que? |
|-----------|-------|----------|
| `kernel='rbf'` | Radial Basis Function | **NÃ£o-linear:** Mapeia dados para espaÃ§o de alta dimensÃ£o onde sÃ£o linearmente separÃ¡veis. Alternativas: `'linear'` (mais rÃ¡pido, assume separabilidade linear), `'poly'` (polinomial, caro computacionalmente). |
| `C=1.0` | PenalizaÃ§Ã£o padrÃ£o | **Trade-off:** C alto â†’ Margem estreita (overfitting). C baixo â†’ Margem larga (underfitting). 1.0 Ã© balanceado. |
| `probability=True` | Habilita probabilidades | **NecessÃ¡rio para ROC-AUC:** `predict()` retorna classes (0, 1). `predict_proba()` retorna probabilidades (0.0-1.0). Aumenta tempo de treino (~2x), mas essencial para mÃ©tricas. |

**PCA Opcional (ReduÃ§Ã£o de Dimensionalidade):**
```python
if use_pca:
    pca = PCA(n_components=2)  # Reduz para 2 dimensÃµes
    X_train_pca = pca.fit_transform(X_train_scaled)
```
- **Por que PCA?** SVM Ã© O(nÂ² a nÂ³) em nÃºmero de amostras. Com muitas features, treino fica lento. PCA reduz features mantendo variÃ¢ncia.
- **Trade-off:** Perda de informaÃ§Ã£o. 2 componentes podem capturar 80% da variÃ¢ncia, mas 20% Ã© perdido.

---

#### **3. MÃ©tricas de AvaliaÃ§Ã£o (`util_metrics.py`)**

```python
metrics = {
    'accuracy': accuracy_score(y_true, y_pred),
    'precision': precision_score(y_true, y_pred, average='macro'),
    'recall': recall_score(y_true, y_pred, average='macro'),
    'f1_score': f1_score(y_true, y_pred, average='macro'),
    'roc_auc': roc_auc_score(y_true, y_prob, multi_class='ovr', average='macro')
}
```

**Por que mÃºltiplas mÃ©tricas?**

| MÃ©trica | O que mede | Quando usar |
|---------|------------|-------------|
| **AcurÃ¡cia** | % de prediÃ§Ãµes corretas | Classes balanceadas. **Cuidado:** 90% acurÃ¡cia em dataset com 90% classe A = modelo inÃºtil (prediz sempre A). |
| **PrecisÃ£o** | % de positivos previstos que sÃ£o realmente positivos | Falsos positivos sÃ£o caros. Ex: spam (marcar email legÃ­timo como spam). |
| **Recall** | % de positivos reais que foram identificados | Falsos negativos sÃ£o caros. Ex: diagnÃ³stico de cÃ¢ncer (nÃ£o detectar doenÃ§a). |
| **F1-Score** | MÃ©dia harmÃ´nica de PrecisÃ£o e Recall | Trade-off entre FP e FN. Classes desbalanceadas. |
| **ROC-AUC** | Ãrea sob curva ROC (varia de 0 a 1) | Avalia performance em diferentes thresholds. 1.0 = perfeito, 0.5 = aleatÃ³rio. |


---


### **Parte 3: Algoritmo GenÃ©tico**

```bash
make part3
```

*(ImplementaÃ§Ã£o e decisÃµes tÃ©cnicas serÃ£o adicionadas)*

---

## Resultados e ComparaÃ§Ãµes

### Visualizar Resultados

```bash
make results
```

Este comando exibe:
- **RelatÃ³rio comparativo** (`comparison_report.txt`) com mÃ©tricas de todos os algoritmos
- **Benchmark CSV** (`benchmark_results.csv`) com dados tabulares
- **Matrizes de confusÃ£o** (`.png`) para anÃ¡lise visual de erros
- **GrÃ¡fico de seleÃ§Ã£o de K** (KNN) mostrando por que K=5 foi escolhido
- **VisualizaÃ§Ã£o da Decision Tree** (estrutura completa da Ã¡rvore)

### InterpretaÃ§Ã£o dos Resultados

**ComparaÃ§Ã£o TÃ­pica (Water Quality Dataset):**

| Algoritmo | AcurÃ¡cia Teste | Tempo Treino | Overfitting | Interpretabilidade |
|-----------|----------------|--------------|-------------|-------------------|
| **Decision Tree** | ~98.7% | ~0.45s | Baixo (0.008%) | â­â­â­â­â­ |
| **KNN** | ~92.6% | ~0.23s | MÃ©dio (2.8%) | â­â­ |
| **SVM** | ~95.0% | ~590s | Baixo (-0.07%) | â­ |

**AnÃ¡lise:**
- **Decision Tree:** Melhor acurÃ¡cia e interpretabilidade. RÃ¡pida de treinar. **Escolha ideal para este dataset.**
- **KNN:** Treino rÃ¡pido, mas performance inferior. Overfitting moderado (decora padrÃµes locais do treino).
- **SVM:** Boa acurÃ¡cia, mas treino MUITO lento (10 minutos para 100k linhas). Modelo "black box" (difÃ­cil interpretar).

**Por que Decision Tree venceu aqui?**
1. **Dataset tabular com features numÃ©ricas:** Ãrvores sÃ£o naturalmente adequadas para dados estruturados.
2. **InteraÃ§Ãµes nÃ£o-lineares:** Ãgua potÃ¡vel depende de combinaÃ§Ãµes (ex: pH alto + Cloro baixo = nÃ£o potÃ¡vel).
3. **Dados limpos:** Poucas outliers extremas, entÃ£o robustez do KNN nÃ£o foi necessÃ¡ria.
4. **Interpretabilidade requerida:** Podemos extrair regras (ex: "SE Hardness < 200 E Solids > 20000 ENTÃƒO potÃ¡vel").

---

## Estrutura de Arquivos Gerados

```
data/processed/
â”œâ”€â”€ benchmark_results.csv           # MÃ©tricas de todos os treinos
â”œâ”€â”€ comparison_report.txt           # RelatÃ³rio formatado
â”œâ”€â”€ confusion_matrix_dt_100000.png  # Matriz de confusÃ£o (Decision Tree)
â”œâ”€â”€ confusion_matrix_knn_100000.png # Matriz de confusÃ£o (KNN)
â”œâ”€â”€ confusion_matrix_svm_100000.png # Matriz de confusÃ£o (SVM)
â”œâ”€â”€ decision_tree_visualization_100000.png  # Ãrvore completa
â”œâ”€â”€ knn_k_selection.png             # GrÃ¡fico de seleÃ§Ã£o de K
â”œâ”€â”€ X_train.csv                     # Features de treino (nÃ£o escalonadas)
â”œâ”€â”€ X_train_scaled.csv              # Features de treino (escalonadas)
â”œâ”€â”€ X_test.csv                      # Features de teste (nÃ£o escalonadas)
â”œâ”€â”€ X_test_scaled.csv               # Features de teste (escalonadas)
â”œâ”€â”€ y_train.csv                     # Labels de treino
â””â”€â”€ y_test.csv                      # Labels de teste
```


---

## ReferÃªncias 

- **"Introduction to Machine Learning with Python"** - Andreas MÃ¼ller & Sarah Guido
  - CapÃ­tulos 2-3: PrÃ©-processamento e validaÃ§Ã£o
  - CapÃ­tulo 5: Decision Trees, KNN, SVM
- **"Hands-On Machine Learning"** - AurÃ©lien GÃ©ron
  - CapÃ­tulo 6: Decision Trees e Random Forests
  - CapÃ­tulo 5: SVM e Kernel Trick

### DocumentaÃ§Ã£o Oficial
- [scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [pandas Documentation](https://pandas.pydata.org/docs/)

---

## LicenÃ§a e Autoria

**Disciplina:** InteligÃªncia Artificial (2025/2)  
**Professor:** Tiago Alves de Oliveira  
**InstituiÃ§Ã£o:** Cefet-MG DivinÃ³polis
**Alunos:** JoÃ£o Pedro Rodrigues Silva e Samuel Silva Gomes

---

## Contato

Para dÃºvidas ou sugestÃµes, abra uma issue no repositÃ³rio ou entre em contato com os autores.

